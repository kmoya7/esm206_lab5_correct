---
title: "Lab 5"
author: "Katheryn Moya"
date: "10/26/2021"
output: 
  html_document: 
    toc: yes
    theme: yeti
    number_sections: yes
    code_folding: hide
---

```{r setup, include=FALSE, warning = FALSE, message = FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```


# confidence intervals

In this section we'll learn to use the `t.test()`function as a way to return the confidence interval using teh t-distribution.

## example 1

create a mock sample of observation values and find the confidence interval. then we'll learn how to report that. - communicating outcomes will become a really important part of the course now.

```{r}
pika_mass <- c(82, 94, 110, 70, 86, 99, 102)

pika_mean <- mean(pika_mass)

pika_sd <- sd(pika_mass)

# want to get confidence interval as a measure of uncertainty

pika_ci <- t.test(pika_mass)

pika_ci
```
### risky and tedious way:
Mean pika mass at Paiute Pass is 91.9 g $\pm$ 13.5 g (mean $\pm$ 1 standard deviation, n = 7) with a 95% confidence interval of [79.4, 104.4]g. # why might this be concerning? prone to human error, especially when updating the original information

### a high initial investment, but safer and better way

In-line code referencing to stored objects!

Use a single backtick on either side of a lowercase r to create an in-line but of code. 

Mean pika mass at Paiute Pass is `r round(pika_mean,1)` g $\pm$ `r round(pika_sd, 1)` g (mean $\pm$ 1 standard deviation, n = `r length(pika_mass)`) with a 95% confindence intercal of [`r pika_ci$conf.int[1]`, `r pika_ci$conf.int[2]`] g.

# Two-sample t-test

Use a two-sample t-test to test the null hypothesis that samples were drawn from populations with the same mean (difference in means = 0)

- H0 : Means difference = 0
- HA: Means difference is NOT - 0

##Example 1

```{r}

oak_trees <- c(29,19,22,30,35,16,20,7)

pine_trees <- c(48, 32, 41, 40, 56, 70, 30, 19, 20)

```
Is there a significant difference in mean heights for oak and pine trees?

```{r}
#run a t-test

trees_t <- t.test(oak_trees, pine_trees) 
```

The p-value of `r trees_t$p.value` means that there is `r (trees_t$p.value) * 100` % chance of finding sample means *at least as different as those I found* by random chance if they were drawn from populations with the same mean height.

would you reject it? still too likely to happen by random chance - not super unlikely to have happened enough that it's sufficient evidence to reject null hypothesis

## Example 2

Using `mpg` dataset to compare city gas mileage for SUVs and compact cars

```{r}
#dataset that only includes suvs and compact cars called compact_suv

compact_suv <- mpg %>% #starting from data frame then
  filter(class %in% c("suv", "compact")) #to filter out rows, check XX column, then %in%, check in console using `unique()`
```

```{r}
#create two different plots, side by side histograms and side by side quantile quantile plots

ggplot(data = compact_suv, aes(x = cty)) +
  geom_histogram(bins = 12) +
  facet_wrap ( ~ class)

ggplot(data = compact_suv, aes(sample = cty)) +
  geom_qq() +
  facet_wrap (~ class)
```


```{r}
#make a summary table

car_stats <- compact_suv %>% 
  group_by(class) %>% 
  summarize(mean_city = mean(cty),
            sd_city = sd(cty),
            sample_size = n())

car_stats
```

```{r}
compact_sample <- compact_suv %>% 
  filter(class == "compact") %>% 
  pull(cty)

suv_sample <- compact_suv %>% 
  filter(class == "suv") %>% 
  pull(cty)

cars_t <- t.test(compact_sample, suv_sample)
```

stats speak: reject the null hypothesis of equal mean city gas mileage

Mean gas mileage for compact cars and SUVs differs significantly (t(`r cars_t$parameter`) = `r cars_t$statistic`, p , 0.001, $\alpha$ = 0.05)
